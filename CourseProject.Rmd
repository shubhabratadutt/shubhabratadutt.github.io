---
title: "Practical Machine learning Course Project"
author: "shubhabratadutt"
date: "Sunday, May 24, 2015"
output: html_document
---


##Objective##

The objective of this project is to develop a predictor for physical exercise effectiveness given 
the sensor data captured from wearable devices. The training and test data for this project 
has been sources from http://groupware.les.inf.puc-rio.br/har


##Data Loading and Preparation##

The following steps are executing for loading and preparing the 
data sets:
1. Training and Test data sets are loaded
2. Covariates with near zero variability are removed as they do not contribute
   much to the prediction.
3. Covariates with more than 80% mssing values are also removed for the same reason.
```{r, cache=TRUE}
library(caret)
library(ggplot2)

#Loading the training and test data sets
trainingSet <- read.csv("pml-training.csv", na.strings=c("NA",""), header=TRUE)
testSet <- read.csv("pml-testing.csv", na.strings=c("NA",""), header=TRUE)

nonNAs <- function(x) {
  as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}

# Build vector of missing data or NA columns to drop.
colcnts <- nonNAs(trainingSet)
drops <- c()
for (cnt in 1:length(colcnts)) {
  if (colcnts[cnt] < nrow(trainingSet)) {
    drops <- c(drops, colnames(trainingSet)[cnt])
  }
}

# Drop NA data and the first 7 columns as they're unnecessary for predicting.
trainingSet <- trainingSet[,!(names(trainingSet) %in% drops)]
trainingSet <- trainingSet[,8:length(colnames(trainingSet))]

testSet <- testSet[,!(names(testSet) %in% drops)]
testSet <- testSet[,8:length(colnames(testSet))]

#Check Near Zero Covariates from the training set
nearZeroVars <- nearZeroVar(trainingSet, saveMetrics = T)
nearZeroVars
```

None of the predicors are near zero vriance and hence will not be removed.

##Model Selection##

We will try Boosting and Random Forest models.
The model will be selected based on better accuracy.
The trining data set is partitioned into two parts, one for training
and the other for testing.

```{r, cache=TRUE}
set.seed(4444)
inTrain <- createDataPartition(y=trainingSet$classe, p=0.6, list=FALSE)
myTraining <- trainingSet[inTrain, ]
myTesting <- trainingSet[-inTrain, ]
```

###Boosting with 4 fold cross validation###
```{r, cache=TRUE}
set.seed(4444)
boostFit <- train(classe ~ ., method = "gbm", data = myTraining, preProcess=c("center", "scale"),
                  verbose = F, trControl = trainControl(method = "cv", number = 4))
predictionsMyTraining <- predict(boostFit, newdata=myTraining)
cm1 <- confusionMatrix(predictionsMyTraining, myTraining$classe)
cm1
#In sample accuracy
cm1$overall[1]

#Applying the model to the testing subset of the original 
#training set
predictionsMyTesting <- predict(boostFit, newdata=myTesting)
cm2 <- confusionMatrix(predictionsMyTesting, myTesting$classe)
cm2
#Out of sample accuracy
cm2$overall[1]

```

The in sample accuracy is 0.9756 while the out of sample accuracy is 0.962 when
using Boosting based prediction model.

###Random forest with 4 fold cross validation###
```{r, cache=TRUE}
set.seed(4444)
rfFit <- train(classe ~ ., method = "rf", data = myTraining, preProcess=c("center", "scale"), 
               verbose = F, trControl = trainControl(method = "cv", number = 4))
predictionsMyTrainingRf <- predict(rfFit, newdata=myTraining)
cm3 <- confusionMatrix(predictionsMyTrainingRf, myTraining$classe)
cm3
#In sample accuracy
cm3$overall[1]

#Applying the model to the testing subset of the original 
#training set
predictionsMyTestingRf <- predict(rfFit, newdata=myTesting)
cm4 <- confusionMatrix(predictionsMyTestingRf, myTesting$classe)
cm4
#Out of sample accuracy
cm4$overall[1]
````

The in sample accuracy is 1.0 while the out of sample accuracy is 0.992 when
using Random Forest based prediction model.

###Predicting with the selected model###
We chose to proceed with the model based on Random Forest as it has better 
accuracy.

```{r}
#Predicting the outcome, classe, for the 20 observations
#in the orignally provided test data set.
predictionsTest <- predict(rfFit, newdata=testSet)
predictionsTest
```

###Generating the answer files for submission###
```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsTest)
```



